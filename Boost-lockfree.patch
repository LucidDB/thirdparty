diff -Naur boost-old/boost/lockfree/atomic_int.hpp boost/boost/lockfree/atomic_int.hpp
--- boost-old/boost/lockfree/atomic_int.hpp	1969-12-31 16:00:00.000000000 -0800
+++ boost/boost/lockfree/atomic_int.hpp	2009-12-04 21:22:29.000000000 -0800
@@ -0,0 +1,233 @@
+//  Copyright (C) 2007, 2008 Tim Blechmann & Thomas Grill
+//
+//  Distributed under the Boost Software License, Version 1.0. (See
+//  accompanying file LICENSE_1_0.txt or copy at
+//  http://www.boost.org/LICENSE_1_0.txt)
+
+//  Disclaimer: Not a Boost library.
+
+#ifndef BOOST_LOCKFREE_ATOMIC_INT_HPP
+#define BOOST_LOCKFREE_ATOMIC_INT_HPP
+
+#include <boost/lockfree/detail/prefix.hpp>
+#include <boost/lockfree/detail/cas.hpp>
+#include <boost/lockfree/detail/branch_hints.hpp>
+#include <boost/noncopyable.hpp>
+
+namespace boost
+{
+namespace lockfree
+{
+
+#if defined(__GNUC__) && ( (__GNUC__ > 4) || ((__GNUC__ >= 4) && (__GNUC_MINOR__ >= 2)) ) || __INTEL_COMPILER
+
+template <typename T>
+class atomic_int:
+    boost::noncopyable
+{
+public:
+    explicit atomic_int(T v = 0):
+        value(v)
+    {}
+
+    operator T(void) const
+    {
+        return __sync_fetch_and_add(&value, 0);
+    }
+
+    void operator =(T v)
+    {
+        value = v;
+        __sync_synchronize();
+    }
+
+    T operator +=(T v)
+    {
+        return __sync_add_and_fetch(&value, v);
+    }
+
+    T operator -=(T v)
+    {
+        return __sync_sub_and_fetch(&value, v);
+    }
+
+    /* prefix operator */
+    T operator ++(void)
+    {
+        return __sync_add_and_fetch(&value, 1);
+    }
+
+    /* prefix operator */
+    T operator --(void)
+    {
+        return __sync_sub_and_fetch(&value, 1);
+    }
+
+    /* postfix operator */
+    T operator ++(int)
+    {
+        return __sync_fetch_and_add(&value, 1);
+    }
+
+    /* postfix operator */
+    T operator --(int)
+    {
+        return __sync_fetch_and_sub(&value, 1);
+    }
+
+private:
+    mutable T value;
+};
+
+#elif defined(__GLIBCPP__) || defined(__GLIBCXX__)
+
+template <typename T>
+class atomic_int:
+    boost::noncopyable
+{
+public:
+    explicit atomic_int(T v = 0):
+        value(v)
+    {}
+
+    operator T(void) const
+    {
+        return __gnu_cxx::__exchange_and_add(&value, 0);
+    }
+
+    void operator =(T v)
+    {
+        value = v;
+        memory_barrier();
+    }
+
+    T operator +=(T v)
+    {
+        return __gnu_cxx::__exchange_and_add(&value, v) + v;
+    }
+
+    T operator -=(T v)
+    {
+        return __gnu_cxx::__exchange_and_add(&value, -v) - v;
+    }
+
+    /* prefix operator */
+    T operator ++(void)
+    {
+        return operator+=(1);
+    }
+
+    /* prefix operator */
+    T operator --(void)
+    {
+        return operator-=(1);
+    }
+
+    /* postfix operator */
+    T operator ++(int)
+    {
+        return __gnu_cxx::__exchange_and_add(&value, 1);
+    }
+
+    /* postfix operator */
+    T operator --(int)
+    {
+        return __gnu_cxx::__exchange_and_add(&value, -1);
+    }
+
+private:
+    mutable _Atomic_word value;
+};
+
+#else /* emulate via atomic_cas */
+
+template <typename T>
+class atomic_int:
+    boost::noncopyable
+{
+public:
+    explicit atomic_int(T v = 0)
+    {
+        *this = v;
+    }
+
+    operator T(void) const
+    {
+        memory_barrier();
+        return value;
+    }
+
+    void operator =(T v)
+    {
+        value = v;
+        memory_barrier();
+    }
+
+    /* prefix operator */
+    T operator ++()
+    {
+        return *this += 1;
+    }
+
+    /* prefix operator */
+    T operator --()
+    {
+        return *this -= 1;
+    }
+
+    T operator +=(T v)
+    {
+        for(;;)
+        {
+            T oldv = value;
+            T newv = oldv + v;
+            if(likely(cas(&value, oldv, newv)))
+                return newv;
+        }
+    }
+
+    T operator -=(T v)
+    {
+        for(;;)
+        {
+            T oldv = value;
+            T newv = oldv - v;
+
+            if(likely(cas(&value, oldv, newv)))
+                return newv;
+        }
+    }
+
+    /* postfix operator */
+    T operator ++(int)
+    {
+        for(;;)
+        {
+            T oldv = value;
+            if(likely(cas(&value, oldv, oldv+1)))
+                return oldv;
+        }
+    }
+
+    /* postfix operator */
+    T operator --(int)
+    {
+        for(;;)
+        {
+            T oldv = value;
+            if(likely(cas(&value, oldv, oldv-1)))
+                return oldv;
+        }
+    }
+
+private:
+    T value;
+};
+
+
+#endif
+
+} /* namespace lockfree */
+} /* namespace boost */
+
+#endif /* BOOST_LOCKFREE_ATOMIC_INT_HPP */
diff -Naur boost-old/boost/lockfree/detail/branch_hints.hpp boost/boost/lockfree/detail/branch_hints.hpp
--- boost-old/boost/lockfree/detail/branch_hints.hpp	1969-12-31 16:00:00.000000000 -0800
+++ boost/boost/lockfree/detail/branch_hints.hpp	2009-12-04 21:21:51.000000000 -0800
@@ -0,0 +1,40 @@
+//  branch hints
+//  Copyright (C) 2007, 2008 Tim Blechmann
+//
+//  Distributed under the Boost Software License, Version 1.0. (See
+//  accompanying file LICENSE_1_0.txt or copy at
+//  http://www.boost.org/LICENSE_1_0.txt)
+
+//  Disclaimer: Not a Boost library.
+
+#ifndef BOOST_LOCKFREE_BRANCH_HINTS_HPP_INCLUDED
+#define BOOST_LOCKFREE_BRANCH_HINTS_HPP_INCLUDED
+
+namespace boost
+{
+namespace lockfree
+{
+    /** \brief hint for the branch prediction */
+    inline bool likely(bool expr)
+    {
+#ifdef __GNUC__
+        return __builtin_expect(expr, true);
+#else
+        return expr;
+#endif
+    }
+
+    /** \brief hint for the branch prediction */
+    inline bool unlikely(bool expr)
+    {
+#ifdef __GNUC__
+        return __builtin_expect(expr, false);
+#else
+        return expr;
+#endif
+    }
+
+} /* namespace lockfree */
+} /* namespace boost */
+
+#endif /* BOOST_LOCKFREE_BRANCH_HINTS_HPP_INCLUDED */
diff -Naur boost-old/boost/lockfree/detail/cas.hpp boost/boost/lockfree/detail/cas.hpp
--- boost-old/boost/lockfree/detail/cas.hpp	1969-12-31 16:00:00.000000000 -0800
+++ boost/boost/lockfree/detail/cas.hpp	2009-12-04 21:21:52.000000000 -0800
@@ -0,0 +1,231 @@
+//  Copyright (C) 2007, 2008, 2009 Tim Blechmann & Thomas Grill
+//
+//  Distributed under the Boost Software License, Version 1.0. (See
+//  accompanying file LICENSE_1_0.txt or copy at
+//  http://www.boost.org/LICENSE_1_0.txt)
+
+//  Disclaimer: Not a Boost library.
+
+#ifndef BOOST_LOCKFREE_CAS_HPP_INCLUDED
+#define BOOST_LOCKFREE_CAS_HPP_INCLUDED
+
+#include <boost/lockfree/detail/prefix.hpp>
+#include <boost/interprocess/detail/atomic.hpp>
+#include <boost/detail/lightweight_mutex.hpp>
+#include <boost/static_assert.hpp>
+
+#include <boost/cstdint.hpp>
+
+#include <boost/mpl/map.hpp>
+#include <boost/mpl/at.hpp>
+#include <boost/mpl/if.hpp>
+#include <boost/mpl/long.hpp>
+
+#ifdef __SSE2__
+#include "emmintrin.h"
+#endif
+
+namespace boost
+{
+namespace lockfree
+{
+
+inline void memory_barrier(void)
+{
+#if defined(__SSE2__)
+    _mm_mfence();
+#elif defined(__GNUC__) && ( (__GNUC__ > 4) || ((__GNUC__ >= 4) &&      \
+                                                (__GNUC_MINOR__ >= 1))) \
+    || defined(__INTEL_COMPILER)
+    __sync_synchronize();
+#elif defined(_MSC_VER) && (_MSC_VER >= 1300)
+    _ReadWriteBarrier();
+#elif defined(__APPLE__)
+    OSMemoryBarrier();
+#elif defined(__GNUC__) && defined (__i386__)
+    asm volatile("lock; addl $0,0(%%esp)":::"memory");
+#elif defined(AO_HAVE_nop_full)
+    AO_nop_full();
+#else
+#   warning "no memory barrier implemented for this platform"
+#endif
+}
+
+inline void read_memory_barrier(void)
+{
+#if defined(__SSE2__)
+    _mm_lfence();
+#else
+    memory_barrier();
+#endif
+}
+
+template <typename C>
+struct atomic_cas_emulator
+{
+    static inline bool cas(volatile C * addr, C old, C nw)
+    {
+        static boost::detail::lightweight_mutex guard;
+        boost::detail::lightweight_mutex::scoped_lock lock(guard);
+
+        C * address = (C*) addr;
+
+        if (*address == old)
+        {
+            *address = nw;
+            return true;
+        }
+        else
+            return false;
+    }
+
+    typedef C cas_type;
+};
+
+
+template <typename C>
+inline bool atomic_cas_emulation(volatile C * addr, C old, C nw)
+{
+    return atomic_cas_emulator<C>::cas(addr, old, nw);
+}
+
+using boost::uint32_t;
+using boost::uint64_t;
+
+struct atomic_cas32
+{
+    static inline bool cas(volatile uint32_t * addr,
+                           uint32_t const & old,
+                           uint32_t const & nw)
+    {
+#if defined(__GCC_HAVE_SYNC_COMPARE_AND_SWAP_4) || defined(__INTEL_COMPILER)
+        return __sync_bool_compare_and_swap(addr, old, nw);
+#elif defined(__APPLE__)
+        return OSAtomicCompareAndSwap32Barrier(old, nw, addr);
+#else
+        return boost::interprocess::detail::atomic_cas32(addr, nw, old) == old;
+#endif
+    }
+    typedef uint32_t cas_type;
+
+    static const bool is_lockfree = true;
+};
+
+struct atomic_cas64
+{
+    typedef uint64_t cas_type;
+
+    static inline bool cas(volatile uint64_t * addr,
+                           uint64_t const & old,
+                           uint64_t const & nw)
+    {
+#if defined(__GCC_HAVE_SYNC_COMPARE_AND_SWAP_8) ||                    \
+    (defined(__GNUC__) && ((__GNUC__ >  4) || ((__GNUC__ == 4) && (__GNUC_MINOR__ > 1)          \
+                       || ((__GNUC__ == 4) && (__GNUC_MINOR__ == 1)))) && defined(__x86_64__))  \
+    || defined(__INTEL_COMPILER)
+        return __sync_bool_compare_and_swap(addr, old, nw);
+#elif defined(_M_IX86)
+        return InterlockedCompareExchange64(reinterpret_cast<volatile LONGLONG*>(addr),
+                                            reinterpret_cast<LONGLONG>(nw),
+                                            reinterpret_cast<LONGLONG>(old)) == old;
+#elif defined(_M_X64)
+        return InterlockedCompareExchange64(reinterpret_cast<volatile LONGLONG*>(addr),
+                                            reinterpret_cast<LONGLONG>(nw),
+                                            reinterpret_cast<LONGLONG>(old)) == old;
+#elif defined(__APPLE__)
+        return OSAtomicCompareAndSwap64Barrier(old, nw, addr);
+#else
+#define CAS_BLOCKING
+        return atomic_cas_emulation((uint64_t *)addr, old, nw);
+#endif
+    }
+
+#ifdef CAS_BLOCKING
+#undef CAS_BLOCKING
+    static const bool is_lockfree = false;
+#else
+    static const bool is_lockfree = true;
+#endif
+};
+
+struct atomic_cas128
+{
+#if defined(__GCC_HAVE_SYNC_COMPARE_AND_SWAP_16)
+    typedef int cas_type __attribute__ ((mode (TI)));
+#else
+    struct cas_type
+    {
+        bool operator==(cas_type const & rhs)
+        {
+            return (data[0] == rhs.data[0]) &&
+                (data[1] == rhs.data[1]);
+        }
+
+        uint64_t data[2];
+    };
+#endif
+
+    static inline bool cas(volatile cas_type * addr, cas_type const & old, cas_type const & nw)
+    {
+#if defined(__GCC_HAVE_SYNC_COMPARE_AND_SWAP_16)
+        return __sync_bool_compare_and_swap_16(addr, old, nw);
+#else
+#define CAS_BLOCKING
+        return atomic_cas_emulation((cas_type*)addr, old, nw);
+#endif
+    }
+
+#ifdef CAS_BLOCKING
+#undef CAS_BLOCKING
+    static const bool is_lockfree = false;
+#else
+    static const bool is_lockfree = true;
+#endif
+};
+
+namespace detail
+{
+using namespace boost::mpl;
+
+template<typename C>
+struct atomic_cas
+{
+private:
+    typedef map3<pair<long_<4>, atomic_cas32>,
+        pair<long_<8>, atomic_cas64>,
+        pair<long_<16>, atomic_cas128>
+        > cas_map;
+
+    typedef typename at<cas_map, long_<sizeof(C)> >::type atomic_cas_t;
+
+    typedef typename if_<has_key<cas_map, long_<sizeof(C)> >,
+        atomic_cas_t,
+        atomic_cas_emulator<C> >::type cas_t;
+
+    typedef typename cas_t::cas_type cas_value_t;
+
+public:
+    static inline bool cas(volatile C * addr, C const & old, C const & nw)
+    {
+        return cas_t::cas((volatile cas_value_t*)addr,
+                          *(cas_value_t*)&old,
+                          *(cas_value_t*)&nw);
+    }
+
+    static const bool is_lockfree = cas_t::is_lockfree;
+};
+
+} /* namespace detail */
+
+using detail::atomic_cas;
+
+template <typename C>
+inline bool cas(volatile C * addr, C const & old, C const & nw)
+{
+    return atomic_cas<C>::cas(addr, old, nw);
+}
+
+} /* namespace lockfree */
+} /* namespace boost */
+
+#endif /* BOOST_LOCKFREE_CAS_HPP_INCLUDED */
diff -Naur boost-old/boost/lockfree/detail/freelist.hpp boost/boost/lockfree/detail/freelist.hpp
--- boost-old/boost/lockfree/detail/freelist.hpp	1969-12-31 16:00:00.000000000 -0800
+++ boost/boost/lockfree/detail/freelist.hpp	2009-12-04 21:21:54.000000000 -0800
@@ -0,0 +1,328 @@
+//  lock-free freelist
+//
+//  Copyright (C) 2008, 2009 Tim Blechmann
+//
+//  Distributed under the Boost Software License, Version 1.0. (See
+//  accompanying file LICENSE_1_0.txt or copy at
+//  http://www.boost.org/LICENSE_1_0.txt)
+
+//  Disclaimer: Not a Boost library.
+
+#ifndef BOOST_LOCKFREE_FREELIST_HPP_INCLUDED
+#define BOOST_LOCKFREE_FREELIST_HPP_INCLUDED
+
+#include <boost/lockfree/detail/tagged_ptr.hpp>
+#include <boost/lockfree/atomic_int.hpp>
+#include <boost/noncopyable.hpp>
+
+#include <boost/mpl/map.hpp>
+#include <boost/mpl/apply.hpp>
+#include <boost/mpl/at.hpp>
+#include <boost/type_traits/is_pod.hpp>
+
+#include <algorithm>            /* for std::min */
+
+namespace boost
+{
+namespace lockfree
+{
+namespace detail
+{
+
+template <typename T, typename Alloc = std::allocator<T> >
+class dummy_freelist:
+    private boost::noncopyable,
+    private Alloc
+{
+public:
+    T * allocate (void)
+    {
+        return Alloc::allocate(1);
+    }
+
+    void deallocate (T * n)
+    {
+        Alloc::deallocate(n, 1);
+    }
+};
+
+} /* namespace detail */
+
+/** simple freelist implementation  */
+template <typename T,
+          std::size_t maximum_size = 64,
+          typename Alloc = std::allocator<T> >
+class freelist:
+    private detail::dummy_freelist<T, Alloc>
+{
+    struct freelist_node
+    {
+        lockfree::tagged_ptr<freelist_node> next;
+    };
+
+    typedef lockfree::tagged_ptr<freelist_node> tagged_ptr;
+
+public:
+    freelist(void):
+        pool_(NULL)
+    {}
+
+    explicit freelist(std::size_t initial_nodes):
+        pool_(NULL)
+    {
+        for (std::size_t i = 0; i != std::min(initial_nodes, maximum_size); ++i)
+        {
+            T * node = detail::dummy_freelist<T, Alloc>::allocate();
+            deallocate(node);
+        }
+    }
+
+    ~freelist(void)
+    {
+        free_memory_pool();
+    }
+
+    T * allocate (void)
+    {
+        for(;;)
+        {
+            tagged_ptr old_pool(pool_);
+
+            if (!old_pool)
+                return detail::dummy_freelist<T, Alloc>::allocate();
+
+            freelist_node * new_pool = old_pool->next.get_ptr();
+
+            if (pool_.cas(old_pool, new_pool))
+            {
+                --free_list_size;
+                return reinterpret_cast<T*>(old_pool.get_ptr());
+            }
+        }
+    }
+
+    void deallocate (T * n)
+    {
+        if (free_list_size > maximum_size)
+        {
+            detail::dummy_freelist<T, Alloc>::deallocate(n);
+            return;
+        }
+
+        for(;;)
+        {
+            tagged_ptr old_pool (pool_);
+
+            freelist_node * new_pool = reinterpret_cast<freelist_node*>(n);
+
+            new_pool->next.set_ptr(old_pool.get_ptr());
+
+            if (pool_.cas(old_pool, new_pool))
+            {
+                --free_list_size;
+                return;
+            }
+        }
+    }
+
+private:
+    void free_memory_pool(void)
+    {
+        tagged_ptr current (pool_);
+
+        while (current)
+        {
+            freelist_node * n = current.get_ptr();
+            current.set(current->next);
+            detail::dummy_freelist<T, Alloc>::deallocate(reinterpret_cast<T*>(n));
+        }
+    }
+
+    tagged_ptr pool_;
+    atomic_int<unsigned long> free_list_size;
+};
+
+template <typename T, typename Alloc = std::allocator<T> >
+class caching_freelist:
+    private detail::dummy_freelist<T, Alloc>
+{
+    struct freelist_node
+    {
+        lockfree::tagged_ptr<freelist_node> next;
+    };
+
+    typedef lockfree::tagged_ptr<freelist_node> tagged_ptr;
+
+public:
+    caching_freelist(void):
+        pool_(NULL)
+    {}
+
+    explicit caching_freelist(std::size_t initial_nodes):
+        pool_(NULL)
+    {
+        for (std::size_t i = 0; i != initial_nodes; ++i)
+        {
+            T * node = detail::dummy_freelist<T, Alloc>::allocate();
+            deallocate(node);
+        }
+    }
+
+    ~caching_freelist(void)
+    {
+        free_memory_pool();
+    }
+
+    T * allocate (void)
+    {
+        for(;;)
+        {
+            tagged_ptr old_pool(pool_);
+
+            if (!old_pool)
+                return detail::dummy_freelist<T, Alloc>::allocate();
+
+            read_memory_barrier();
+            freelist_node * new_pool = old_pool->next.get_ptr();
+
+            if (pool_.cas(old_pool, new_pool)) {
+                void * ptr = old_pool.get_ptr();
+                return reinterpret_cast<T*>(ptr);
+            }
+        }
+    }
+
+    void deallocate (T * n)
+    {
+        void * node = n;
+        for(;;)
+        {
+            tagged_ptr old_pool (pool_);
+
+            freelist_node * new_pool = reinterpret_cast<freelist_node*>(node);
+
+            new_pool->next.set_ptr(old_pool.get_ptr());
+
+            if (pool_.cas(old_pool,new_pool))
+                return;
+        }
+    }
+
+private:
+    void free_memory_pool(void)
+    {
+        tagged_ptr current (pool_);
+
+        while (current)
+        {
+            void * n = current.get_ptr();
+            current.set(current->next);
+            detail::dummy_freelist<T, Alloc>::deallocate(reinterpret_cast<T*>(n));
+        }
+    }
+
+    volatile tagged_ptr pool_;
+};
+
+template <typename T, typename Alloc = std::allocator<T> >
+class static_freelist:
+    private Alloc
+{
+    struct freelist_node
+    {
+        lockfree::tagged_ptr<freelist_node> next;
+    };
+
+    typedef lockfree::tagged_ptr<freelist_node> tagged_ptr;
+
+public:
+    explicit static_freelist(std::size_t max_nodes):
+        pool_(NULL), total_nodes(max_nodes)
+    {
+        chunks = Alloc::allocate(max_nodes);
+        for (std::size_t i = 0; i != max_nodes; ++i)
+        {
+            T * node = chunks + i;
+            deallocate(node);
+        }
+    }
+
+    ~static_freelist(void)
+    {
+        Alloc::deallocate(chunks, total_nodes);
+    }
+
+    T * allocate (void)
+    {
+        for(;;)
+        {
+            tagged_ptr old_pool(pool_);
+
+            if (!old_pool)
+                return 0;       /* allocation fails */
+
+            read_memory_barrier();
+            freelist_node * new_pool = old_pool->next.get_ptr();
+
+            if (pool_.cas(old_pool, new_pool)) {
+                void * ptr = old_pool.get_ptr();
+                return reinterpret_cast<T*>(ptr);
+            }
+        }
+    }
+
+    void deallocate (T * n)
+    {
+        void * node = n;
+        for(;;)
+        {
+            tagged_ptr old_pool (pool_);
+
+            freelist_node * new_pool = reinterpret_cast<freelist_node*>(node);
+
+            new_pool->next.set_ptr(old_pool.get_ptr());
+
+            if (pool_.cas(old_pool,new_pool))
+                return;
+        }
+    }
+
+private:
+    volatile tagged_ptr pool_;
+
+    const std::size_t total_nodes;
+    T* chunks;
+};
+
+
+struct caching_freelist_t {};
+struct static_freelist_t {};
+
+namespace detail
+{
+
+#if 0
+template <typename T, typename Alloc, typename tag>
+struct select_freelist
+{
+private:
+    typedef typename Alloc::template rebind<T>::other Allocator;
+
+    typedef typename boost::lockfree::caching_freelist<T, Allocator> cfl;
+    typedef typename boost::lockfree::static_freelist<T, Allocator> sfl;
+
+    typedef typename boost::mpl::map<
+        boost::mpl::pair < caching_freelist_t, cfl/* typename boost::lockfree::caching_freelist<T, Alloc> */ >,
+        boost::mpl::pair < static_freelist_t,  sfl/* typename boost::lockfree::static_freelist<T, Alloc> */ >,
+        int
+        > freelists;
+public:
+    typedef typename boost::mpl::at<freelists, tag>::type type;
+};
+#endif
+
+} /* namespace detail */
+} /* namespace lockfree */
+} /* namespace boost */
+
+#endif /* BOOST_LOCKFREE_FREELIST_HPP_INCLUDED */
diff -Naur boost-old/boost/lockfree/detail/prefix.hpp boost/boost/lockfree/detail/prefix.hpp
--- boost-old/boost/lockfree/detail/prefix.hpp	1969-12-31 16:00:00.000000000 -0800
+++ boost/boost/lockfree/detail/prefix.hpp	2009-12-04 21:21:54.000000000 -0800
@@ -0,0 +1,80 @@
+//  Copyright (C) 2007, 2008, 2009 Tim Blechmann & Thomas Grill
+//
+//  Distributed under the Boost Software License, Version 1.0. (See
+//  accompanying file LICENSE_1_0.txt or copy at
+//  http://www.boost.org/LICENSE_1_0.txt)
+
+//  Disclaimer: Not a Boost library.
+
+#ifndef BOOST_LOCKFREE_PREFIX_HPP_INCLUDED
+#define BOOST_LOCKFREE_PREFIX_HPP_INCLUDED
+
+#include <cassert>
+
+
+#ifdef _WIN32
+    #include <windows.h>
+#endif
+
+#ifdef __APPLE__
+    #include <libkern/OSAtomic.h>
+#endif
+
+#define BOOST_LOCKFREE_CACHELINE_BYTES 64
+
+#ifdef _MSC_VER
+// \note: Must use /Oi option for VC++ to enable intrinsics
+    extern "C" {
+        void __cdecl _ReadWriteBarrier();
+        LONG __cdecl _InterlockedCompareExchange(LONG volatile* Dest,LONG Exchange, LONG Comp);
+    }
+
+#define BOOST_LOCKFREE_CACHELINE_ALIGNMENT __declspec(align(BOOST_LOCKFREE_CACHELINE_BYTES))
+
+#if defined(_M_IX86)
+    #define BOOST_LOCKFREE_DCAS_ALIGNMENT
+#elif defined(_M_X64) || defined(_M_IA64)
+    #define BOOST_LOCKFREE_PTR_COMPRESSION 1
+    #define BOOST_LOCKFREE_DCAS_ALIGNMENT __declspec(align(16))
+#endif
+
+#endif /* _MSC_VER */
+
+#ifdef __GNUC__
+
+#define BOOST_LOCKFREE_CACHELINE_ALIGNMENT __attribute__((aligned(BOOST_LOCKFREE_CACHELINE_BYTES)))
+
+#ifdef __i386__
+    #define BOOST_LOCKFREE_DCAS_ALIGNMENT
+#elif defined(__ppc__)
+    #define BOOST_LOCKFREE_DCAS_ALIGNMENT
+#elif defined(__x86_64__)
+
+    #if !(defined (__GCC_HAVE_SYNC_COMPARE_AND_SWAP_16))
+        #define BOOST_LOCKFREE_PTR_COMPRESSION 1
+    #endif
+    #define BOOST_LOCKFREE_DCAS_ALIGNMENT __attribute__((aligned(16)))
+#endif
+
+
+#if (__GNUC__ > 4) || ((__GNUC__ == 4) && (__GNUC_MINOR__ >= 2))
+#include <ext/atomicity.h>
+#else
+#include <bits/atomicity.h>
+#endif
+
+
+#endif /* __GNUC__ */
+
+
+#ifdef USE_ATOMIC_OPS
+    #define AO_REQUIRE_CAS
+    #define AO_USE_PENTIUM4_INSTRS
+
+    extern "C" {
+        #include "../libatomic_ops/src/atomic_ops.h"
+    }
+#endif
+
+
+#endif /* BOOST_LOCKFREE_PREFIX_HPP_INCLUDED */
diff -Naur boost-old/boost/lockfree/detail/tagged_ptr_dcas.hpp boost/boost/lockfree/detail/tagged_ptr_dcas.hpp
--- boost-old/boost/lockfree/detail/tagged_ptr_dcas.hpp	1969-12-31 16:00:00.000000000 -0800
+++ boost/boost/lockfree/detail/tagged_ptr_dcas.hpp	2009-12-04 21:21:56.000000000 -0800
@@ -0,0 +1,171 @@
+//  tagged pointer, for aba prevention
+//
+//  Copyright (C) 2008 Tim Blechmann
+//
+//  Distributed under the Boost Software License, Version 1.0. (See
+//  accompanying file LICENSE_1_0.txt or copy at
+//  http://www.boost.org/LICENSE_1_0.txt)
+
+//  Disclaimer: Not a Boost library.
+
+#ifndef BOOST_LOCKFREE_TAGGED_PTR_DCAS_HPP_INCLUDED
+#define BOOST_LOCKFREE_TAGGED_PTR_DCAS_HPP_INCLUDED
+
+#include <boost/lockfree/detail/cas.hpp>
+#include <boost/lockfree/detail/branch_hints.hpp>
+
+#include <cstddef>              /* for std::size_t */
+
+namespace boost
+{
+namespace lockfree
+{
+
+template <class T>
+class BOOST_LOCKFREE_DCAS_ALIGNMENT tagged_ptr
+{
+public:
+    typedef std::size_t tag_t;
+
+    static const bool is_lockfree = boost::lockfree::atomic_cas<tagged_ptr>::is_lockfree;
+
+    /** uninitialized constructor */
+    tagged_ptr(void)//: ptr(0), tag(0)
+    {}
+
+    /** copy constructor */
+    tagged_ptr(volatile tagged_ptr const & p)//: ptr(0), tag(0)
+    {
+        set(p);
+    }
+
+    explicit tagged_ptr(T * p, tag_t t = 0):
+        ptr(p), tag(t)
+    {}
+
+    /** atomic set operations */
+    /* @{ */
+    void operator= (tagged_ptr const & p)
+    {
+        set(p);
+    }
+
+    void atomic_set(tagged_ptr const & p)
+    {
+        for (;;)
+        {
+            tagged_ptr old;
+            old.set(*this);
+            if(likely(cas(old, p.ptr, p.tag)))
+                return;
+        }
+    }
+
+    void atomic_set(T * p, tag_t t)
+    {
+        for (;;)
+        {
+            tagged_ptr old;
+            old.set(*this);
+
+            if(likely(cas(old, p, t)))
+                return;
+        }
+    }
+    /* @} */
+
+    /** unsafe set operation */
+    /* @{ */
+    void set(volatile tagged_ptr const & p)
+    {
+        ptr = p.ptr;
+        tag = p.tag;
+    }
+
+    void set(T * p, tag_t t)
+    {
+        ptr = p;
+        tag = t;
+    }
+    /* @} */
+
+    /** comparing semantics */
+    /* @{ */
+    bool operator== (volatile tagged_ptr const & p) const
+    {
+        return (ptr == p.ptr) && (tag == p.tag);
+    }
+
+    bool operator!= (volatile tagged_ptr const & p) const
+    {
+        return !operator==(p);
+    }
+    /* @} */
+
+    /** pointer access */
+    /* @{ */
+    T * get_ptr(void) const volatile
+    {
+        return ptr;
+    }
+
+    void set_ptr(T * p) volatile
+    {
+        ptr = p;
+    }
+    /* @} */
+
+    /** tag access */
+    /* @{ */
+    tag_t get_tag() const volatile
+    {
+        return tag;
+    }
+
+    void set_tag(tag_t t) volatile
+    {
+        tag = t;
+    }
+    /* @} */
+
+    /** compare and swap  */
+    /* @{ */
+    bool cas(tagged_ptr const & oldval, T * newptr) volatile
+    {
+        return cas(oldval, newptr, oldval.tag + 1);
+    }
+
+    bool cas(tagged_ptr const & oldval, T * newptr, tag_t t) volatile
+    {
+        tagged_ptr newval(newptr, t);
+        return boost::lockfree::atomic_cas<tagged_ptr>::cas(this, oldval, newval);
+    }
+    /* @} */
+
+    /** smart pointer support  */
+    /* @{ */
+    T & operator*() const
+    {
+        return *ptr;
+    }
+
+    T * operator->() const
+    {
+        return ptr;
+    }
+
+    operator bool(void) const
+    {
+        return ptr != 0;
+    }
+    /* @} */
+
+protected:
+    T * ptr;
+    tag_t tag;
+};
+
+} /* namespace lockfree */
+} /* namespace boost */
+
+#endif /* BOOST_LOCKFREE_TAGGED_PTR_DCAS_HPP_INCLUDED */
diff -Naur boost-old/boost/lockfree/detail/tagged_ptr.hpp boost/boost/lockfree/detail/tagged_ptr.hpp
--- boost-old/boost/lockfree/detail/tagged_ptr.hpp	1969-12-31 16:00:00.000000000 -0800
+++ boost/boost/lockfree/detail/tagged_ptr.hpp	2009-12-04 21:21:55.000000000 -0800
@@ -0,0 +1,22 @@
+//  tagged pointer, for aba prevention
+//
+//  Copyright (C) 2008 Tim Blechmann
+//
+//  Distributed under the Boost Software License, Version 1.0. (See
+//  accompanying file LICENSE_1_0.txt or copy at
+//  http://www.boost.org/LICENSE_1_0.txt)
+
+//  Disclaimer: Not a Boost library.
+
+#ifndef BOOST_LOCKFREE_TAGGED_PTR_HPP_INCLUDED
+#define BOOST_LOCKFREE_TAGGED_PTR_HPP_INCLUDED
+
+#include <boost/lockfree/detail/prefix.hpp>
+
+#ifndef BOOST_LOCKFREE_PTR_COMPRESSION
+#include <boost/lockfree/detail/tagged_ptr_dcas.hpp>
+#else
+#include <boost/lockfree/detail/tagged_ptr_ptrcompression.hpp>
+#endif
+
+#endif /* BOOST_LOCKFREE_TAGGED_PTR_HPP_INCLUDED */
diff -Naur boost-old/boost/lockfree/detail/tagged_ptr_ptrcompression.hpp boost/boost/lockfree/detail/tagged_ptr_ptrcompression.hpp
--- boost-old/boost/lockfree/detail/tagged_ptr_ptrcompression.hpp	1969-12-31 16:00:00.000000000 -0800
+++ boost/boost/lockfree/detail/tagged_ptr_ptrcompression.hpp	2009-12-04 21:21:57.000000000 -0800
@@ -0,0 +1,203 @@
+//  tagged pointer, for aba prevention
+//
+//  Copyright (C) 2008, 2009 Tim Blechmann, based on code by Cory Nelson
+//
+//  Distributed under the Boost Software License, Version 1.0. (See
+//  accompanying file LICENSE_1_0.txt or copy at
+//  http://www.boost.org/LICENSE_1_0.txt)
+
+//  Disclaimer: Not a Boost library.
+
+#ifndef BOOST_LOCKFREE_TAGGED_PTR_PTRCOMPRESSION_HPP_INCLUDED
+#define BOOST_LOCKFREE_TAGGED_PTR_PTRCOMPRESSION_HPP_INCLUDED
+
+#include <boost/lockfree/detail/cas.hpp>
+#include <boost/lockfree/detail/branch_hints.hpp>
+
+#include <cstddef>              /* for std::size_t */
+
+#include <boost/cstdint.hpp>
+
+namespace boost
+{
+namespace lockfree
+{
+
+#if defined (__x86_64__) || defined (_M_X64)
+
+template <class T>
+class BOOST_LOCKFREE_DCAS_ALIGNMENT tagged_ptr
+{
+    typedef boost::uint64_t compressed_ptr_t;
+    typedef boost::uint16_t tag_t;
+
+private:
+    union cast_unit
+    {
+        compressed_ptr_t value;
+        tag_t tag[4];
+    };
+
+    static const int tag_index = 3;
+    static const compressed_ptr_t ptr_mask = 0xffffffffffff; //(1L<<48L)-1;
+
+    static T* extract_ptr(volatile compressed_ptr_t const & i)
+    {
+        return (T*)(i & ptr_mask);
+    }
+
+    static tag_t extract_tag(volatile compressed_ptr_t const & i)
+    {
+        cast_unit cu;
+        cu.value = i;
+        return cu.tag[tag_index];
+    }
+
+    static compressed_ptr_t pack_ptr(T * ptr, int tag)
+    {
+        cast_unit ret;
+        ret.value = compressed_ptr_t(ptr);
+        ret.tag[tag_index] = tag;
+        return ret.value;
+    }
+
+public:
+    static const bool is_lockfree = boost::lockfree::atomic_cas<compressed_ptr_t>::is_lockfree;
+
+    /** uninitialized constructor */
+    tagged_ptr(void)//: ptr(0), tag(0)
+    {}
+
+    /** copy constructor */
+    tagged_ptr(volatile tagged_ptr const & p)//: ptr(0), tag(0)
+    {
+        set(p);
+    }
+
+    explicit tagged_ptr(T * p, tag_t t = 0):
+        ptr(pack_ptr(p, t))
+    {}
+
+    /** atomic set operations */
+    /* @{ */
+    void operator= (tagged_ptr const & p)
+    {
+        atomic_set(p);
+    }
+
+    void atomic_set(tagged_ptr const & p)
+    {
+        set(p);
+    }
+
+    void atomic_set(T * p, tag_t t)
+    {
+        ptr = pack_ptr(p, t);
+    }
+    /* @} */
+
+    /** unsafe set operation */
+    /* @{ */
+    void set(volatile tagged_ptr const & p)
+    {
+        ptr = p.ptr;
+    }
+
+    void set(T * p, tag_t t)
+    {
+        ptr = pack_ptr(p, t);
+    }
+    /* @} */
+
+    /** comparing semantics */
+    /* @{ */
+    bool operator== (volatile tagged_ptr const & p) const
+    {
+        return (ptr == p.ptr);
+    }
+
+    bool operator!= (volatile tagged_ptr const & p) const
+    {
+        return !operator==(p);
+    }
+    /* @} */
+
+    /** pointer access */
+    /* @{ */
+    T * get_ptr() const volatile
+    {
+        return extract_ptr(ptr);
+    }
+
+    void set_ptr(T * p) volatile
+    {
+        tag_t tag = get_tag();
+        ptr = pack_ptr(p, tag);
+    }
+    /* @} */
+
+    /** tag access */
+    /* @{ */
+    tag_t get_tag() const volatile
+    {
+        return extract_tag(ptr);
+    }
+
+    void set_tag(tag_t t) volatile
+    {
+        T * p = get_ptr();
+        ptr = pack_ptr(p, t);
+    }
+    /* @} */
+
+    /** compare and swap  */
+    /* @{ */
+private:
+    bool cas(compressed_ptr_t const & oldval, compressed_ptr_t const & newval) volatile
+    {
+        return boost::lockfree::atomic_cas<compressed_ptr_t>::cas(&(this->ptr), oldval, newval);
+    }
+
+public:
+    bool cas(tagged_ptr const & oldval, T * newptr) volatile
+    {
+        compressed_ptr_t new_compressed_ptr = pack_ptr(newptr, extract_tag(oldval.ptr)+1);
+        return cas(oldval.ptr, new_compressed_ptr);
+    }
+
+    bool cas(tagged_ptr const & oldval, T * newptr, tag_t t) volatile
+    {
+        compressed_ptr_t new_compressed_ptr = pack_ptr(newptr, t);
+        return boost::lockfree::atomic_cas<compressed_ptr_t>::cas(&(this->ptr), oldval.ptr, new_compressed_ptr);
+    }
+    /* @} */
+
+    /** smart pointer support  */
+    /* @{ */
+    T & operator*() const
+    {
+        return *get_ptr();
+    }
+
+    T * operator->() const
+    {
+        return get_ptr();
+    }
+
+    operator bool(void) const
+    {
+        return get_ptr() != 0;
+    }
+    /* @} */
+
+protected:
+    compressed_ptr_t ptr;
+};
+#else
+#error unsupported platform
+#endif
+
+} /* namespace lockfree */
+} /* namespace boost */
+
+#endif /* BOOST_LOCKFREE_TAGGED_PTR_PTRCOMPRESSION_HPP_INCLUDED */
diff -Naur boost-old/boost/lockfree/fifo.hpp boost/boost/lockfree/fifo.hpp
--- boost-old/boost/lockfree/fifo.hpp	1969-12-31 16:00:00.000000000 -0800
+++ boost/boost/lockfree/fifo.hpp	2009-12-04 21:22:31.000000000 -0800
@@ -0,0 +1,288 @@
+//  lock-free fifo queue from
+//  Michael, M. M. and Scott, M. L.,
+//  "simple, fast and practical non-blocking and blocking concurrent queue algorithms"
+//
+//  implementation for c++
+//
+//  Copyright (C) 2008 Tim Blechmann
+//
+//  Distributed under the Boost Software License, Version 1.0. (See
+//  accompanying file LICENSE_1_0.txt or copy at
+//  http://www.boost.org/LICENSE_1_0.txt)
+
+//  Disclaimer: Not a Boost library.
+
+#ifndef BOOST_LOCKFREE_FIFO_HPP_INCLUDED
+#define BOOST_LOCKFREE_FIFO_HPP_INCLUDED
+
+#include <boost/lockfree/atomic_int.hpp>
+#include <boost/lockfree/detail/tagged_ptr.hpp>
+#include <boost/lockfree/detail/freelist.hpp>
+
+#include <boost/static_assert.hpp>
+#include <boost/type_traits/is_pod.hpp>
+
+#include <memory>               /* std::auto_ptr */
+#include <boost/scoped_ptr.hpp>
+#include <boost/shared_ptr.hpp>
+#include <boost/noncopyable.hpp>
+
+namespace boost
+{
+namespace lockfree
+{
+
+namespace detail
+{
+
+template <typename T, typename freelist_t, typename Alloc>
+class fifo:
+    boost::noncopyable
+{
+    BOOST_STATIC_ASSERT(boost::is_pod<T>::value);
+
+    struct BOOST_LOCKFREE_CACHELINE_ALIGNMENT node
+    {
+        typedef tagged_ptr<node> tagged_ptr_t;
+
+        node(T const & v):
+            data(v)
+        {
+            next.set(NULL, next.get_tag()+1); /* increment tag to avoid ABA problem */
+        }
+
+        node (void):
+            next(NULL)
+        {}
+
+        tagged_ptr_t next;
+        T data;
+    };
+
+    typedef tagged_ptr<node> atomic_node_ptr;
+
+    typedef typename Alloc::template rebind<node>::other node_allocator;
+/*     typedef typename select_freelist<node, node_allocator, freelist_t>::type pool_t; */
+
+    typedef typename boost::mpl::if_<boost::is_same<freelist_t, caching_freelist_t>,
+                                     caching_freelist<node, node_allocator>,
+                                     static_freelist<node, node_allocator>
+                                     >::type pool_t;
+
+public:
+    static const bool is_lockfree = node::tagged_ptr_t::is_lockfree;
+
+    fifo(void):
+        pool(128)
+    {
+        node * n = alloc_node();
+        head_.set_ptr(n);
+        tail_.set_ptr(n);
+    }
+
+    explicit fifo(std::size_t initial_nodes):
+        pool(initial_nodes)
+    {
+        node * n = alloc_node();
+        head_.set_ptr(n);
+        tail_.set_ptr(n);
+    }
+
+    ~fifo(void)
+    {
+        if (!empty())
+        {
+            T dummy;
+            for(;;)
+            {
+                if (!dequeue(&dummy))
+                    break;
+            }
+        }
+        dealloc_node(head_.get_ptr());
+    }
+
+    bool empty(void)
+    {
+        return head_.get_ptr() == tail_.get_ptr();
+    }
+
+    bool enqueue(T const & t)
+    {
+        node * n = alloc_node(t);
+
+        if (n == NULL)
+            return false;
+
+        for (;;)
+        {
+            atomic_node_ptr tail (tail_);
+            read_memory_barrier();
+            atomic_node_ptr next (tail->next);
+
+            if (likely(tail == tail_))
+            {
+                if (next.get_ptr() == 0)
+                {
+                    if ( tail->next.cas(next, n) )
+                    {
+                        tail_.cas(tail, n);
+                        return true;
+                    }
+                }
+                else
+                    tail_.cas(tail, next.get_ptr());
+            }
+        }
+    }
+
+    bool dequeue (T * ret)
+    {
+        for (;;)
+        {
+            atomic_node_ptr head (head_);
+            read_memory_barrier();
+
+            atomic_node_ptr tail(tail_);
+            node * next = head->next.get_ptr();
+            read_memory_barrier();
+
+            if (likely(head == head_))
+            {
+                if (head.get_ptr() == tail.get_ptr())
+                {
+                    if (next == 0)
+                        return false;
+
+                    tail_.cas(tail, next);
+                }
+                else
+                {
+                    *ret = next->data;
+                    if (head_.cas(head, next))
+                    {
+                        dealloc_node(head.get_ptr());
+
+                        return true;
+                    }
+                }
+            }
+        }
+    }
+
+private:
+    node * alloc_node(void)
+    {
+        node * chunk = pool.allocate();
+        new(chunk) node();
+        return chunk;
+    }
+
+    node * alloc_node(T const & t)
+    {
+        node * chunk = pool.allocate();
+        new(chunk) node(t);
+        return chunk;
+    }
+
+    void dealloc_node(node * n)
+    {
+        n->~node();
+        pool.deallocate(n);
+    }
+
+    volatile atomic_node_ptr head_;
+    static const int padding_size = 64 - sizeof(atomic_node_ptr); /* cache lines on current cpus seem to
+                                                                   * be 64 byte */
+    char padding1[padding_size];
+    volatile atomic_node_ptr tail_;
+    char padding2[padding_size];
+
+    pool_t pool;
+};
+
+} /* namespace detail */
+
+/** lockfree fifo
+ *
+ *  - wrapper for detail::fifo
+ * */
+template <typename T,
+          typename freelist_t = caching_freelist_t,
+          typename Alloc = std::allocator<T>
+          >
+class fifo:
+    public detail::fifo<T, freelist_t, Alloc>
+{
+public:
+    fifo(void)
+    {}
+
+    explicit fifo(std::size_t initial_nodes):
+        detail::fifo<T, freelist_t, Alloc>(initial_nodes)
+    {}
+};
+
+
+/** lockfree fifo, template specialization for pointer-types
+ *
+ *  - wrapper for detail::fifo
+ *  - overload dequeue to support smart pointers
+ * */
+template <typename T, typename freelist_t, typename Alloc>
+class fifo<T*, freelist_t, Alloc>:
+    public detail::fifo<T*, freelist_t, Alloc>
+{
+    typedef detail::fifo<T*, freelist_t, Alloc> fifo_t;
+
+    template <typename smart_ptr>
+    bool dequeue_smart_ptr(smart_ptr & ptr)
+    {
+        T * result = 0;
+        bool success = fifo_t::dequeue(&result);
+
+        if (success)
+            ptr.reset(result);
+        return success;
+    }
+
+public:
+    fifo(void)
+    {}
+
+    explicit fifo(std::size_t initial_nodes):
+        fifo_t(initial_nodes)
+    {}
+
+    bool enqueue(T * t)
+    {
+        return fifo_t::enqueue(t);
+    }
+
+    bool dequeue (T ** ret)
+    {
+        return fifo_t::dequeue(ret);
+    }
+
+    bool dequeue (std::auto_ptr<T> & ret)
+    {
+        return dequeue_smart_ptr(ret);
+    }
+
+    bool dequeue (boost::scoped_ptr<T> & ret)
+    {
+        BOOST_STATIC_ASSERT(sizeof(boost::scoped_ptr<T>) == sizeof(T*));
+        return dequeue(reinterpret_cast<T**>((void*)&ret));
+    }
+
+    bool dequeue (boost::shared_ptr<T> & ret)
+    {
+        return dequeue_smart_ptr(ret);
+    }
+};
+
+} /* namespace lockfree */
+} /* namespace boost */
+
+
+#endif /* BOOST_LOCKFREE_FIFO_HPP_INCLUDED */
diff -Naur boost-old/boost/lockfree/stack.hpp boost/boost/lockfree/stack.hpp
--- boost-old/boost/lockfree/stack.hpp	1969-12-31 16:00:00.000000000 -0800
+++ boost/boost/lockfree/stack.hpp	2009-12-04 21:22:34.000000000 -0800
@@ -0,0 +1,150 @@
+//  Copyright (C) 2008 Tim Blechmann
+//
+//  Distributed under the Boost Software License, Version 1.0. (See
+//  accompanying file LICENSE_1_0.txt or copy at
+//  http://www.boost.org/LICENSE_1_0.txt)
+
+//  Disclaimer: Not a Boost library.
+
+#ifndef BOOST_LOCKFREE_STACK_HPP_INCLUDED
+#define BOOST_LOCKFREE_STACK_HPP_INCLUDED
+
+#include <boost/checked_delete.hpp>
+
+#include <boost/static_assert.hpp>
+#include <boost/type_traits/is_base_of.hpp>
+
+#include <boost/lockfree/detail/tagged_ptr.hpp>
+#include <boost/lockfree/detail/freelist.hpp>
+#include <boost/noncopyable.hpp>
+
+
+namespace boost
+{
+namespace lockfree
+{
+template <typename T,
+          typename freelist_t = caching_freelist_t,
+          typename Alloc = std::allocator<T>
+          >
+class stack:
+    boost::noncopyable
+{
+    struct node
+    {
+        typedef tagged_ptr<node> tagged_ptr_t;
+
+        node(T const & v):
+            v(v)
+        {}
+
+        tagged_ptr_t next;
+        T v;
+    };
+
+    typedef tagged_ptr<node> ptr_type;
+
+    typedef typename Alloc::template rebind<node>::other node_allocator;
+/*     typedef typename detail::select_freelist<node, node_allocator, freelist_t>::type pool_t; */
+
+    typedef typename boost::mpl::if_<boost::is_same<freelist_t, caching_freelist_t>,
+                                     caching_freelist<node, node_allocator>,
+                                     static_freelist<node, node_allocator>
+                                     >::type pool_t;
+
+public:
+    static const bool is_lockfree = node::tagged_ptr_t::is_lockfree;
+
+    stack(void):
+        tos(NULL), pool(128)
+    {}
+
+    explicit stack(std::size_t n):
+        tos(NULL), pool(n)
+    {}
+
+    ~stack(void)
+    {
+        if (!empty())
+        {
+            T dummy;
+            for(;;)
+            {
+                if (!pop(&dummy))
+                    break;
+            }
+        }
+    }
+
+    bool push(T const & v)
+    {
+        node * newnode = alloc_node(v);
+
+        if (newnode == 0)
+            return false;
+
+        ptr_type old_tos;
+        do
+        {
+            old_tos.set(tos);
+            newnode->next.set_ptr(old_tos.get_ptr());
+        }
+        while (!tos.cas(old_tos, newnode));
+
+        return true;
+    }
+
+    bool pop(T * ret)
+    {
+        for (;;)
+        {
+            ptr_type old_tos(tos);
+
+            if (!old_tos)
+                return false;
+            read_memory_barrier();
+
+            node * new_tos = old_tos->next.get_ptr();
+
+            if (tos.cas(old_tos, new_tos))
+            {
+                *ret = old_tos->v;
+                dealloc_node(old_tos.get_ptr());
+                return true;
+            }
+        }
+    }
+
+    bool empty(void) const
+    {
+        return tos.get_ptr() == NULL;
+    }
+
+private:
+    node * alloc_node(T const & t)
+    {
+        node * chunk = pool.allocate();
+        new(chunk) node(t);
+        return chunk;
+    }
+
+    void dealloc_node(node * n)
+    {
+        n->~node();
+        pool.deallocate(n);
+    }
+
+    volatile ptr_type tos;
+
+    static const int padding_size = 64 - sizeof(ptr_type); /* cache lines on current cpus seem to
+                                                            * be 64 byte */
+    char padding[padding_size];
+
+    pool_t pool;
+};
+
+
+} /* namespace lockfree */
+} /* namespace boost */
+
+#endif /* BOOST_LOCKFREE_STACK_HPP_INCLUDED */
